{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b341b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_alunos.json', 'r') as f:\n",
    "    base_alunos = json.load(f)\n",
    "    \n",
    "base_alunos.sort( key = lambda e: e['id'] )\n",
    "base_alunos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25886103",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth_associacao.json', 'r') as f:\n",
    "    ground_truth_associacao = json.load(f)\n",
    "    \n",
    "#ground_truth_associacao = { int(x): ground_truth_associacao[x] for x in ground_truth_associacao}\n",
    "ground_truth_associacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18a156",
   "metadata": {},
   "source": [
    "# Início da Avaliação de OCR de Matrículas com Detect Document Plus Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'ocr/matricula/vision_document_detection_plus_sorting'\n",
    "import os\n",
    "resultados_ocr_matricula_com_ddocplus = []\n",
    "for transcription_file in os.listdir(directory):\n",
    "    if not transcription_file.endswith('txt'):\n",
    "        continue\n",
    "    with open(f'{directory}/{transcription_file}', 'r') as f:\n",
    "        transcription = ''.join(f.readlines())\n",
    "        transcription = transcription.replace('\\n', '')\n",
    "        transcription = transcription.replace(' ', '')\n",
    "        transcription = transcription.replace('MATRICULA', '')\n",
    "        transcription = transcription.replace('MATRÍCULA', '')\n",
    "        transcription = transcription.replace('o', '0')\n",
    "        transcription = transcription.replace('O', '0')\n",
    "        transcription = transcription.replace('I', '1')\n",
    "    resultados_ocr_matricula_com_ddocplus.append( (int(transcription_file.split('_')[0]),transcription) )\n",
    "    \n",
    "resultados_ocr_matricula_com_ddocplus.sort()\n",
    "resultados_ocr_matricula_com_ddocplus = { str(i):j for i,j in resultados_ocr_matricula_com_ddocplus}\n",
    "resultados_ocr_matricula_com_ddocplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda133af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matricula = {}\n",
    "for x in ground_truth_associacao:\n",
    "    matricula = list(filter(lambda e: e['id'] == ground_truth_associacao[x], base_alunos))[0]['matricula']\n",
    "    ground_truth_matricula[x] = matricula\n",
    "    \n",
    "ground_truth_matricula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisamos comparar resultados_ocr_matricula_com_tesseract com ground_truth_matricula\n",
    "for x in resultados_ocr_matricula_com_ddocplus:\n",
    "    print(\"%35s %35s\" %(resultados_ocr_matricula_com_ddocplus[x], ground_truth_matricula[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4becf2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliar quantos são absolutamente iguais\n",
    "comparativo = {i: int(resultados_ocr_matricula_com_ddocplus[str(i)]==ground_truth_matricula[str(i)]) for i in resultados_ocr_matricula_com_ddocplus}\n",
    "comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acuracia absoluta\n",
    "acuracia_absoluta = sum(comparativo.values())/len(comparativo)\n",
    "acuracia_absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa290b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pybind11\n",
    "!pip install fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular os CER's do OCR na matrícula\n",
    "CERs = [ fastwer.score_sent(resultados_ocr_matricula_com_ddocplus[x], ground_truth_matricula[x], char_level=True) \n",
    "         for x in resultados_ocr_matricula_com_ddocplus ]\n",
    "\n",
    "from math import isnan\n",
    "for i,_ in enumerate(CERs):\n",
    "    if isnan(CERs[i]):\n",
    "        CERs[i] = float('inf')\n",
    "CERs.sort()\n",
    "CERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359146ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular o pior, o melhor, o médio, o mediano e os quartis de CER\n",
    "#note que alguns CERs deram infinito pois o cálculo do CER envolve dividir por len(ground_truth), que no caso de alguns formulários, é 0\n",
    "from statistics import mean\n",
    "from statistics import median\n",
    "from statistics import quantiles\n",
    "primeiro_quartil, mediana, segundo_quartil = quantiles(CERs, n=4, method='inclusive')\n",
    "print('Melhor CER:', min(CERs))\n",
    "print('1º quartil CER:',primeiro_quartil)\n",
    "print('CER médio:', mean(CERs))\n",
    "print('CER mediano:',mediana)\n",
    "print('2º quartil CER:',segundo_quartil)\n",
    "print('Pior CER:', max(CERs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f27abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparar cada valor de resultados_ocr_matricula_com_dtext com cada valor da base_alunos\n",
    "associacoes = {}\n",
    "for x in resultados_ocr_matricula_com_ddocplus:\n",
    "    associacoes[x] = min( [ (aluno['id'], \n",
    "                        fastwer.score_sent(resultados_ocr_matricula_com_ddocplus[x], aluno['matricula'], char_level=True))\n",
    "                        for aluno in base_alunos ],\n",
    "                         key = lambda e: e[1])[0]\n",
    "associacoes#é o aluno predicted, para cada formulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90915a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump( associacoes, open( \"modelo_associacoes.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18279eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora queremos comparar quantas vezes predicted == correto\n",
    "#ou seja, precisamos contar quantas vezes associacoes[i] == ground_truth_associacao[i]\n",
    "avaliacao_associacoes = [ associacoes[i]==ground_truth_associacao[i] for i in associacoes]\n",
    "avaliacao_associacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5568cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_associacao = len( list(filter(None, avaliacao_associacoes)) )/ len(avaliacao_associacoes)\n",
    "acuracia_associacao*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5bcb1",
   "metadata": {},
   "source": [
    "# Início da Avaliação de OCR de Nomes com Detect Document Plus Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'ocr/nome/vision_document_detection_plus_sorting'\n",
    "import os\n",
    "resultados_ocr_nome_com_ddocplus = []\n",
    "for transcription_file in os.listdir(directory):\n",
    "    if not transcription_file.endswith('txt'):\n",
    "        continue\n",
    "    with open(f'{directory}/{transcription_file}', 'r') as f:\n",
    "        transcription = ''.join(f.readlines())\n",
    "        transcription = transcription.replace('\\n', '')\n",
    "        transcription = transcription.replace(' ', '')\n",
    "        transcription = transcription.replace('NOME', '')\n",
    "        transcription = transcription.replace('0', 'O')\n",
    "        transcription = transcription.replace('1', 'I')\n",
    "        transcription = transcription.upper()\n",
    "    resultados_ocr_nome_com_ddocplus.append( (int(transcription_file.split('_')[0]),transcription) )\n",
    "    \n",
    "resultados_ocr_nome_com_ddocplus.sort()\n",
    "resultados_ocr_nome_com_ddocplus = { str(i):j for i,j in resultados_ocr_nome_com_ddocplus}\n",
    "resultados_ocr_nome_com_ddocplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_nome = {}\n",
    "for x in ground_truth_associacao:\n",
    "    nome = list(filter(lambda e: e['id'] == ground_truth_associacao[x], base_alunos))[0]['nome']\n",
    "    ground_truth_nome[x] = nome\n",
    "    \n",
    "ground_truth_nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8288a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisamos comparar resultados_ocr_nome_com_dtext com ground_truth_nome\n",
    "for x in resultados_ocr_nome_com_ddocplus:\n",
    "    print(\"%50s %50s\" %(resultados_ocr_nome_com_ddocplus[x], ground_truth_nome[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa08d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliar quantos são absolutamente iguais\n",
    "comparativo = {i: int(resultados_ocr_nome_com_ddocplus[str(i)]==ground_truth_nome[str(i)]) for i in resultados_ocr_nome_com_ddocplus}\n",
    "comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acuracia absoluta\n",
    "acuracia_absoluta = sum(comparativo.values())/len(comparativo)\n",
    "acuracia_absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b84dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pybind11\n",
    "!pip install fastwer\n",
    "import fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular os CER's do OCR nos nomes\n",
    "CERs = [ fastwer.score_sent(resultados_ocr_nome_com_ddocplus[x], ground_truth_nome[x], char_level=True) \n",
    "         for x in resultados_ocr_nome_com_ddocplus ]\n",
    "CERs.sort()\n",
    "CERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular o pior, o melhor, o médio, o mediano e os quartis de CER\n",
    "#note que alguns CERs deram infinito pois o cálculo do CER envolve dividir por len(ground_truth), que no caso de alguns formulários, é 0\n",
    "from statistics import mean\n",
    "from statistics import median\n",
    "from statistics import quantiles\n",
    "primeiro_quartil, mediana, segundo_quartil = quantiles(CERs, n=4, method='inclusive')\n",
    "print('Melhor CER:', min(CERs))\n",
    "print('1º quartil CER:',primeiro_quartil)\n",
    "print('CER médio:', mean(CERs))\n",
    "print('CER mediano:',mediana)\n",
    "print('2º quartil CER:',segundo_quartil)\n",
    "print('Pior CER:', max(CERs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparar cada valor de resultados_ocr_nome_com_tesseract com cada valor da base_alunos\n",
    "associacoes = {}\n",
    "for x in resultados_ocr_nome_com_ddocplus:\n",
    "    associacoes[x] = min( [ (aluno['id'], \n",
    "                        fastwer.score_sent(resultados_ocr_nome_com_ddocplus[x], aluno['nome'], char_level=True))\n",
    "                        for aluno in base_alunos ],\n",
    "                         key = lambda e: e[1])[0]\n",
    "associacoes#é o aluno predicted, para cada formulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195afbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump( associacoes, open( \"modelo_associacoes.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678271f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora queremos comparar quantas vezes predicted == correto\n",
    "#ou seja, precisamos contar quantas vezes associacoes[i] == ground_truth_associacao[i]\n",
    "avaliacao_associacoes = [ associacoes[i]==ground_truth_associacao[i] for i in associacoes]\n",
    "avaliacao_associacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498753c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_associacao = len( list(filter(None, avaliacao_associacoes)) )/ len(avaliacao_associacoes)\n",
    "acuracia_associacao*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414310ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_alunos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b295292",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/vinicius/Documents/tcc/teste1/jsons_predictions'\n",
    "\n",
    "obj = {}\n",
    "for x in resultados_ocr_matricula_com_ddocplus:\n",
    "    #procurar em modelo_associacoes, o cara com a chave x\n",
    "    #o valor dele é o id de aluno a ser buscado na base de alunos\n",
    "    id_aluno_predicted = associacoes[x]\n",
    "    #buscar este id na base_alunos e retornar o objeto de dados correspondente\n",
    "    dados_aluno = list(filter(lambda e:e['id']==id_aluno_predicted, base_alunos))[0]\n",
    "    obj[x] = dados_aluno\n",
    "\n",
    "\n",
    "for x in resultados_ocr_nome_com_ddocplus:\n",
    "    json.dump( obj[x], open( f'{directory}/{x}.json', 'w' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
