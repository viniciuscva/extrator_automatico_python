{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0673306-3a42-46e7-96a8-12cbea8cd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fdd68-6325-4ed0-a26d-9141e3146d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_alunos.json', 'r') as f:\n",
    "    base_alunos = json.load(f)\n",
    "    \n",
    "base_alunos.sort( key = lambda e: e['id'] )\n",
    "base_alunos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80bcad-7f5f-4970-9a05-81da9a0fcbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ground_truth_associacao.json', 'r') as f:\n",
    "    ground_truth_associacao = json.load(f)\n",
    "    \n",
    "#ground_truth_associacao = { int(x): ground_truth_associacao[x] for x in ground_truth_associacao}\n",
    "ground_truth_associacao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15771f-6081-4947-9fd3-f65bb2356b06",
   "metadata": {},
   "source": [
    "# Início da Avaliação de OCR de Matrículas com Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bad394-1837-4cf7-ba1a-73ef4c0a011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'ocr/matricula/tesseract'\n",
    "import os\n",
    "resultados_ocr_matricula_com_tesseract = []\n",
    "for transcription_file in os.listdir(directory):\n",
    "    if not transcription_file.endswith('txt'):\n",
    "        continue\n",
    "    with open(f'{directory}/{transcription_file}', 'r') as f:\n",
    "        transcription = ''.join(f.readlines())\n",
    "        transcription = transcription.replace('\\n', '')\n",
    "        transcription = transcription.replace(' ', '')\n",
    "        transcription = transcription.replace('MATRICULA', '')\n",
    "        transcription = transcription.replace('MATRÍCULA', '')\n",
    "        transcription = transcription.replace('o', '0')\n",
    "        transcription = transcription.replace('O', '0')\n",
    "        transcription = transcription.replace('I', '1')\n",
    "    resultados_ocr_matricula_com_tesseract.append( (int(transcription_file.split('_')[0]),transcription) )\n",
    "    \n",
    "resultados_ocr_matricula_com_tesseract.sort()\n",
    "resultados_ocr_matricula_com_tesseract = { str(i):j for i,j in resultados_ocr_matricula_com_tesseract}\n",
    "resultados_ocr_matricula_com_tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6be93-d45f-43de-a7de-77f08a3c0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_matricula = {}\n",
    "for x in ground_truth_associacao:\n",
    "    matricula = list(filter(lambda e: e['id'] == ground_truth_associacao[x], base_alunos))[0]['matricula']\n",
    "    ground_truth_matricula[x] = matricula\n",
    "    \n",
    "ground_truth_matricula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cddfd-7f98-4542-8036-9f1164a4ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisamos comparar resultados_ocr_matricula_com_tesseract com ground_truth_matricula\n",
    "for x in resultados_ocr_matricula_com_tesseract:\n",
    "    print(\"%35s %35s\" %(resultados_ocr_matricula_com_tesseract[x], ground_truth_matricula[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4bec3-4b49-48ac-bc4b-6197dbd229f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliar quantos são absolutamente iguais\n",
    "comparativo = {i: int(resultados_ocr_matricula_com_tesseract[str(i)]==ground_truth_matricula[str(i)]) for i in resultados_ocr_matricula_com_tesseract}\n",
    "comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7238a86-2c8d-4455-938c-2c82fb47e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acuracia absoluta\n",
    "acuracia_absoluta = sum(comparativo.values())/len(comparativo)\n",
    "acuracia_absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cb509-8fef-4d72-b02a-6893bfc43787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pybind11\n",
    "!pip install fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6b238-b190-4e50-9e67-2697d26d7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba6b4eb-7842-4dd0-bbd3-22d930d53cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular os CER's do OCR na matrícula\n",
    "CERs = [ fastwer.score_sent(resultados_ocr_matricula_com_tesseract[x], ground_truth_matricula[x], char_level=True) \n",
    "         for x in resultados_ocr_matricula_com_tesseract ]\n",
    "CERs.sort()\n",
    "CERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d7df7-59e3-425b-9066-65b3ff14f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular o pior, o melhor, o médio, o mediano e os quartis de CER\n",
    "#note que alguns CERs deram infinito pois o cálculo do CER envolve dividir por len(ground_truth), que no caso de alguns formulários, é 0\n",
    "from statistics import mean\n",
    "from statistics import median\n",
    "from statistics import quantiles\n",
    "primeiro_quartil, mediana, segundo_quartil = quantiles(CERs, n=4, method='inclusive')\n",
    "print('Melhor CER:', min(CERs))\n",
    "print('1º quartil CER:',primeiro_quartil)\n",
    "print('CER médio:', mean(CERs))\n",
    "print('CER mediano:',mediana)\n",
    "print('2º quartil CER:',segundo_quartil)\n",
    "print('Pior CER:', max(CERs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2088beb-4a9e-45e4-858b-9df1a4d016be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparar cada valor de resulresultados_ocr_matricula_com_tesseract com cada valor da base_alunos\n",
    "associacoes = {}\n",
    "for x in resultados_ocr_matricula_com_tesseract:\n",
    "    associacoes[x] = min( [ (aluno['id'], \n",
    "                        fastwer.score_sent(resultados_ocr_matricula_com_tesseract[x], aluno['matricula'], char_level=True))\n",
    "                        for aluno in base_alunos ],\n",
    "                         key = lambda e: e[1])[0]\n",
    "associacoes#é o aluno predicted, para cada formulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcba36e-63c1-4818-bd70-148ec3effce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora queremos comparar quantas vezes predicted == correto\n",
    "#ou seja, precisamos contar quantas vezes associacoes[i] == ground_truth_associacao[i]\n",
    "avaliacao_associacoes = [ associacoes[i]==ground_truth_associacao[i] for i in associacoes]\n",
    "avaliacao_associacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f0221-fb97-4ea5-aa87-49c8cdcce4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_associacao = len( list(filter(None, avaliacao_associacoes)) )/ len(avaliacao_associacoes)\n",
    "acuracia_associacao*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d8b0b-b281-4c38-b526-7ee84afc60fb",
   "metadata": {},
   "source": [
    "# Início da Avaliação de OCR de Nomes com Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2fdf3-bdbc-42b2-a418-c031b370d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'ocr/nome/tesseract'\n",
    "import os\n",
    "resultados_ocr_nome_com_tesseract = []\n",
    "for transcription_file in os.listdir(directory):\n",
    "    if not transcription_file.endswith('txt'):\n",
    "        continue\n",
    "    with open(f'{directory}/{transcription_file}', 'r') as f:\n",
    "        transcription = ''.join(f.readlines())\n",
    "        transcription = transcription.replace('\\n', '')\n",
    "        transcription = transcription.replace(' ', '')\n",
    "        transcription = transcription.replace('NOME', '')\n",
    "        transcription = transcription.replace('0', 'O')\n",
    "        transcription = transcription.replace('1', 'I')\n",
    "        transcription = transcription.upper()\n",
    "    resultados_ocr_nome_com_tesseract.append( (int(transcription_file.split('_')[0]),transcription) )\n",
    "    \n",
    "resultados_ocr_nome_com_tesseract.sort()\n",
    "resultados_ocr_nome_com_tesseract = { str(i):j for i,j in resultados_ocr_nome_com_tesseract}\n",
    "resultados_ocr_nome_com_tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fee00-0927-4fbb-8960-edd0074c2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_nome = {}\n",
    "for x in ground_truth_associacao:\n",
    "    nome = list(filter(lambda e: e['id'] == ground_truth_associacao[x], base_alunos))[0]['nome']\n",
    "    ground_truth_nome[x] = nome\n",
    "    \n",
    "ground_truth_nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6fa04-d118-4efe-a2eb-1f04976522b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisamos comparar resultados_ocr_nome_com_tesseract com ground_truth_nome\n",
    "for x in resultados_ocr_nome_com_tesseract:\n",
    "    print(\"%35s %35s\" %(resultados_ocr_nome_com_tesseract[x], ground_truth_nome[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2fa7f0-0b91-48bc-96af-cbeb6ba61f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliar quantos são absolutamente iguais\n",
    "comparativo = {i: int(resultados_ocr_nome_com_tesseract[str(i)]==ground_truth_nome[str(i)]) for i in resultados_ocr_nome_com_tesseract}\n",
    "comparativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94dd4d-9959-4690-a7fe-123c91f98951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acuracia absoluta\n",
    "acuracia_absoluta = sum(comparativo.values())/len(comparativo)\n",
    "acuracia_absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83094d-9a32-435c-9ed9-c0fe4ce93b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pybind11\n",
    "!pip install fastwer\n",
    "import fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a40bba-65ab-4641-a1e8-b84272fb0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular os CER's do OCR nos nomes\n",
    "CERs = [ fastwer.score_sent(resultados_ocr_nome_com_tesseract[x], ground_truth_nome[x], char_level=True) \n",
    "         for x in resultados_ocr_nome_com_tesseract ]\n",
    "CERs.sort()\n",
    "CERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b6d5a-e7f5-44e4-a501-cd318bc8d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular o pior, o melhor, o médio, o mediano e os quartis de CER\n",
    "#note que alguns CERs deram infinito pois o cálculo do CER envolve dividir por len(ground_truth), que no caso de alguns formulários, é 0\n",
    "from statistics import mean\n",
    "from statistics import median\n",
    "from statistics import quantiles\n",
    "primeiro_quartil, mediana, segundo_quartil = quantiles(CERs, n=4, method='inclusive')\n",
    "print('Melhor CER:', min(CERs))\n",
    "print('1º quartil CER:',primeiro_quartil)\n",
    "print('CER médio:', mean(CERs))\n",
    "print('CER mediano:',mediana)\n",
    "print('2º quartil CER:',segundo_quartil)\n",
    "print('Pior CER:', max(CERs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0e3ed-8fe8-4a2c-873b-cda8923acddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparar cada valor de resultados_ocr_nome_com_tesseract com cada valor da base_alunos\n",
    "associacoes = {}\n",
    "for x in resultados_ocr_nome_com_tesseract:\n",
    "    associacoes[x] = min( [ (aluno['id'], \n",
    "                        fastwer.score_sent(resultados_ocr_nome_com_tesseract[x], aluno['nome'], char_level=True))\n",
    "                        for aluno in base_alunos ],\n",
    "                         key = lambda e: e[1])[0]\n",
    "associacoes#é o aluno predicted, para cada formulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573d99e-b5ed-4622-8790-43fdb4c03d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora queremos comparar quantas vezes predicted == correto\n",
    "#ou seja, precisamos contar quantas vezes associacoes[i] == ground_truth_associacao[i]\n",
    "avaliacao_associacoes = [ associacoes[i]==ground_truth_associacao[i] for i in associacoes]\n",
    "avaliacao_associacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1f96a-e8cc-4c18-a919-1e45f66e6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_associacao = len( list(filter(None, avaliacao_associacoes)) )/ len(avaliacao_associacoes)\n",
    "acuracia_associacao*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
